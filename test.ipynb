{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from evaluation.evaluate_audiocaps import calculate_sisdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Keyword arguments {'duration': 5} are not expected by AudioLDMPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenDict([('vae', ('diffusers', 'AutoencoderKL')), ('text_encoder', ('transformers', 'ClapTextModelWithProjection')), ('tokenizer', ('transformers', 'RobertaTokenizerFast')), ('unet', ('diffusers', 'UNet2DConditionModel')), ('scheduler', ('diffusers', 'DDIMScheduler')), ('vocoder', ('transformers', 'SpeechT5HifiGan')), ('_name_or_path', 'cvssp/audioldm')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from diffusers import AudioLDMPipeline\n",
    "pipe = AudioLDMPipeline.from_pretrained('cvssp/audioldm', use_safetensors=False, duration=5)\n",
    "print(dir(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 513, 1024])\n",
      "torch.Size([1, 163840])\n",
      "torch.Size([1, 513, 1025])\n",
      "torch.Size([1, 163680])\n",
      "tensor([[ 0.1390, -0.8076,  0.6340,  ...,  1.0788,  0.0676,  0.9357]])\n",
      "tensor([[ 0.1390, -0.8076,  0.6340,  ..., -0.3549,  0.3887,  0.3911]])\n",
      "121.29343032836914\n",
      "121.29341125488281\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "        self.melbins = 64     # 중복\n",
    "        self.sampling_rate = 16000  # 중복\n",
    "        self.hopsize = 160    # 중복\n",
    "        # self.duration = 10.24\n",
    "        self.duration = 10.24\n",
    "        self.target_length = 1024\n",
    "        self.mixup = 0.0\n",
    "\n",
    "        self.mel_basis = {}\n",
    "        self.hann_window = {}\n",
    "\n",
    "        # DSP: s-full 기준 (audioldm_original.yaml)\n",
    "        self.filter_length = 1024\n",
    "        self.hop_length = 160\n",
    "        self.win_length = 1024\n",
    "        self.n_mel = 64\n",
    "        self.mel_fmin = 0\n",
    "        self.mel_fmax = 8000\n",
    "\n",
    "        self.n_freq = self.filter_length // 2 + 1  # 513\n",
    "        self.sample_length = self.sampling_rate * self.duration  # 163840\n",
    "        self.pad_size = int((self.filter_length - self.hop_length) / 2)  # (1024-160)/2 = 432\n",
    "        self.n_times =  # 123\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn((1,163840))\n",
    "x_stft = torch.stft(x, n_fft=1024, hop_length=160, win_length=1024, window=torch.hann_window(1024), return_complex=True, pad_mode=\"reflect\",)\n",
    "print(x_stft[:,:,:-1].shape)\n",
    "\n",
    "x_reconstruct = torch.istft(x_stft[:,:,:-1], n_fft=1024, hop_length=160, win_length=1024, window=torch.hann_window(1024), return_complex=False,)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_stft.shape)\n",
    "print(x_reconstruct.shape)\n",
    "\n",
    "print(x[:10])\n",
    "print(x_reconstruct[:10])\n",
    "\n",
    "sisdr = calculate_sisdr(x.numpy()[:,:163680], x_reconstruct.numpy())\n",
    "print(sisdr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_stft = torch.stft(x, n_fft=1024, hop_length=160, win_length=1024, window=torch.hann_window(1024), return_complex=True,\n",
    "    # center=False,\n",
    "    pad_mode=\"reflect\",\n",
    ")\n",
    "x_reconstruct = torch.istft(x_stft, n_fft=1024, hop_length=160, \n",
    "win_length=1024, window=torch.hann_window(1024), return_complex=False,\n",
    "    # center=False,\n",
    ")\n",
    "\n",
    "\n",
    "sisdr = calculate_sisdr(x.numpy()[:,:163680], x_reconstruct.numpy()[:,:163680])\n",
    "print(sisdr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 163840])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Size([1, 513, 1018])\n",
    "torch.Size([1, 162720])\n",
    "\n",
    "torch.Size([1, 513, 1025])\n",
    "torch.Size([1, 163840])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
