{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from evaluation.evaluate_audiocaps import calculate_sisdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'duration': 5} are not expected by AudioLDMPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_deprecated_kwargs', '_dict_from_json_file', '_encode_prompt', '_exclude_from_cpu_offload', '_execution_device', '_get_init_keys', '_get_signature_keys', '_get_signature_types', '_internal_dict', '_is_onnx', '_load_connected_pipes', '_optional_components', '_upload_folder', 'check_inputs', 'components', 'config', 'config_name', 'decode_latents', 'device', 'disable_attention_slicing', 'disable_freeu', 'disable_vae_slicing', 'disable_vae_tiling', 'disable_xformers_memory_efficient_attention', 'download', 'dtype', 'enable_attention_slicing', 'enable_freeu', 'enable_model_cpu_offload', 'enable_sequential_cpu_offload', 'enable_vae_slicing', 'enable_vae_tiling', 'enable_xformers_memory_efficient_attention', 'extract_init_dict', 'from_config', 'from_pipe', 'from_pretrained', 'fuse_qkv_projections', 'get_config_dict', 'has_compatibles', 'hf_device_map', 'ignore_for_config', 'load_config', 'maybe_free_model_hooks', 'mel_spectrogram_to_waveform', 'model_cpu_offload_seq', 'name_or_path', 'numpy_to_pil', 'prepare_extra_step_kwargs', 'prepare_latents', 'progress_bar', 'push_to_hub', 'register_modules', 'register_to_config', 'remove_all_hooks', 'reset_device_map', 'save_config', 'save_pretrained', 'scheduler', 'set_attention_slice', 'set_progress_bar_config', 'set_use_memory_efficient_attention_xformers', 'text_encoder', 'to', 'to_json_file', 'to_json_string', 'tokenizer', 'unet', 'unfuse_qkv_projections', 'vae', 'vae_scale_factor', 'vocoder']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from diffusers import AudioLDMPipeline\n",
    "pipe = AudioLDMPipeline.from_pretrained('cvssp/audioldm', use_safetensors=False, duration=5)\n",
    "print(dir(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 513, 1024])\n",
      "torch.Size([1, 163840])\n",
      "torch.Size([1, 513, 1025])\n",
      "torch.Size([1, 163680])\n",
      "tensor([[ 0.1390, -0.8076,  0.6340,  ...,  1.0788,  0.0676,  0.9357]])\n",
      "tensor([[ 0.1390, -0.8076,  0.6340,  ..., -0.3549,  0.3887,  0.3911]])\n",
      "121.29343032836914\n",
      "121.29341125488281\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "        self.melbins = 64     # 중복\n",
    "        self.sampling_rate = 16000  # 중복\n",
    "        self.hopsize = 160    # 중복\n",
    "        # self.duration = 10.24\n",
    "        self.duration = 10.24\n",
    "        self.target_length = 1024\n",
    "        self.mixup = 0.0\n",
    "\n",
    "        self.mel_basis = {}\n",
    "        self.hann_window = {}\n",
    "\n",
    "        # DSP: s-full 기준 (audioldm_original.yaml)\n",
    "        self.filter_length = 1024\n",
    "        self.hop_length = 160\n",
    "        self.win_length = 1024\n",
    "        self.n_mel = 64\n",
    "        self.mel_fmin = 0\n",
    "        self.mel_fmax = 8000\n",
    "\n",
    "        self.n_freq = self.filter_length // 2 + 1  # 513\n",
    "        self.sample_length = self.sampling_rate * self.duration  # 163840\n",
    "        self.pad_size = int((self.filter_length - self.hop_length) / 2)  # (1024-160)/2 = 432\n",
    "        self.n_times =  # 123\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "x = torch.randn((1,163840))\n",
    "x_stft = torch.stft(x, n_fft=1024, hop_length=160, win_length=1024, window=torch.hann_window(1024), return_complex=True, pad_mode=\"reflect\",)\n",
    "print(x_stft[:,:,:-1].shape)\n",
    "\n",
    "x_reconstruct = torch.istft(x_stft[:,:,:-1], n_fft=1024, hop_length=160, win_length=1024, window=torch.hann_window(1024), return_complex=False,)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_stft.shape)\n",
    "print(x_reconstruct.shape)\n",
    "\n",
    "print(x[:10])\n",
    "print(x_reconstruct[:10])\n",
    "\n",
    "sisdr = calculate_sisdr(x.numpy()[:,:163680], x_reconstruct.numpy())\n",
    "print(sisdr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_stft = torch.stft(x, n_fft=1024, hop_length=160, win_length=1024, window=torch.hann_window(1024), return_complex=True,\n",
    "    # center=False,\n",
    "    pad_mode=\"reflect\",\n",
    ")\n",
    "x_reconstruct = torch.istft(x_stft, n_fft=1024, hop_length=160, \n",
    "win_length=1024, window=torch.hann_window(1024), return_complex=False,\n",
    "    # center=False,\n",
    ")\n",
    "\n",
    "\n",
    "sisdr = calculate_sisdr(x.numpy()[:,:163680], x_reconstruct.numpy()[:,:163680])\n",
    "print(sisdr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 163840])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Size([1, 513, 1018])\n",
    "torch.Size([1, 162720])\n",
    "\n",
    "torch.Size([1, 513, 1025])\n",
    "torch.Size([1, 163840])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
